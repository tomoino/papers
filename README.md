# papers
読んだ論文についていろいろまとめる

# 読んだもの
1. [Survey on Recurrent Neural Network in Natural Language Processing](https://www.researchgate.net/publication/319937209_Survey_on_Recurrent_Neural_Network_in_Natural_Language_Processing)
1. [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025)
1. [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)

# 読もうと思っているもの
1. [Attention Is All You Need](https://arxiv.org/abs/1706.03762)